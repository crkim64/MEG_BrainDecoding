import sys
import os
import argparse
import h5py
import numpy as np
from PIL import Image
import torch
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as T
from tqdm import tqdm

# Versatile Diffusion ê²½ë¡œ (í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)
sys.path.append('versatile_diffusion')

# BrainDiffuser ë¼ì´ë¸ŒëŸ¬ë¦¬
from lib.cfg_helper import model_cfg_bank
from lib.model_zoo import get_model

# ==========================================
# 1. ì„¤ì • ë° íŒŒë¼ë¯¸í„°
# ==========================================
parser = argparse.ArgumentParser()
parser.add_argument("--data_dir", default='./data', help="Directory containing HDF5 data")
parser.add_argument("--image_root", default='./data', help="Root folder of raw images")
parser.add_argument("--out_dir", default='./data/extracted_features', help="Output directory")
parser.add_argument("--batch_size", type=int, default=32)
parser.add_argument("--device", default='cuda', help="Device to use")
args = parser.parse_args()

os.makedirs(args.out_dir, exist_ok=True)

# ==========================================
# 2. ì´ë¯¸ì§€ ê²½ë¡œ ë³µì›ìš© Dictionary ë¡œë“œ
# ==========================================
DICT_PATH = os.path.join(args.data_dir, 'image_path_dictionary.h5')
if not os.path.exists(DICT_PATH):
    raise FileNotFoundError(f"ğŸš¨ Dictionary file not found: {DICT_PATH}\nRun 'preprocess_optimized.py' first.")

print(f"ğŸ“š Loading Image Path Dictionary from {DICT_PATH}...")
IMAGE_MAP = {}
with h5py.File(DICT_PATH, 'r') as f:
    cats = f['category_nr'][:]
    exs = f['exemplar_nr'][:]
    paths = f['image_path'][:].astype(str) # byte string -> str ë³€í™˜
    
    for c, e, p in zip(cats, exs, paths):
        IMAGE_MAP[(c, e)] = p

print(f"âœ… Dictionary Loaded. {len(IMAGE_MAP)} unique images.")

# ==========================================
# 3. Dataset ì •ì˜ (HDF5 ê¸°ë°˜)
# ==========================================
class HDF5ImageDataset(Dataset):
    def __init__(self, h5_path, image_root):
        self.h5_path = h5_path
        self.image_root = image_root
        
        # ë©”íƒ€ë°ì´í„° ë¯¸ë¦¬ ë¡œë“œ
        with h5py.File(h5_path, 'r') as f:
            self.category_nr = f['category_nr'][:]
            self.exemplar_nr = f['exemplar_nr'][:]
            self.length = len(self.category_nr)

        # ì „ì²˜ë¦¬: 512x512, [-1, 1]
        self.transform = T.Compose([
            T.Resize((512, 512), interpolation=T.InterpolationMode.BICUBIC),
            T.ToTensor(), 
        ])

    def __len__(self):
        return self.length

    def _get_full_path(self, rel_path):
        """ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ ë° ë³´ì •"""
        # 1. ê¸°ë³¸ ê²½ë¡œ ì‹œë„
        full_path = os.path.join(self.image_root, rel_path)
        if os.path.exists(full_path): return full_path
        
        # 2. images_test_meg -> images_meg ìˆ˜ì • ì‹œë„
        fixed_path = rel_path.replace('images_test_meg', 'images_meg')
        full_path = os.path.join(self.image_root, fixed_path)
        if os.path.exists(full_path): return full_path

        # 3. í´ë” êµ¬ì¡° ì§ì ‘ íƒìƒ‰ (images_meg/{category}/{filename})
        filename = os.path.basename(fixed_path)
        if '_' in filename:
            category = filename.rsplit('_', 1)[0]
            try_path = os.path.join(self.image_root, 'images_meg', category, filename)
            if os.path.exists(try_path): return try_path
            
        return None

    def __getitem__(self, idx):
        # 1. Dictionaryì—ì„œ ê²½ë¡œ ì°¾ê¸°
        cat = self.category_nr[idx]
        ex = self.exemplar_nr[idx]
        
        rel_path = IMAGE_MAP.get((cat, ex), None)
        
        if rel_path is None:
            # ë§¤í•‘ ì‹¤íŒ¨ ì‹œ ê²€ì€ í™”ë©´ (ê±°ì˜ ë°œìƒ ì•ˆ í•¨)
            img = Image.new('RGB', (512, 512))
        else:
            # ê¸°ë³¸ ê²½ë¡œ + Path Recovery ì‹œë„
            full_path = self._get_full_path(rel_path)
            
            # _get_full_pathê°€ ì‹¤íŒ¨í–ˆì„ ê²½ìš° (dictionary path ë¶ˆì¼ì¹˜ ëŒ€ë¹„)
            if not full_path:
                fname = os.path.basename(rel_path)
                if '_' in fname:
                    # e.g., crayon_15s.jpg -> category: crayon
                    # e.g., air_conditioner_01b.jpg -> category: air_conditioner
                    
                    # Try splitting by last underscore first (common case)
                    cat_guess = fname.rsplit('_', 1)[0]
                    fallback_path = os.path.join(self.image_root, 'images_meg', cat_guess, fname)
                    if os.path.exists(fallback_path):
                        full_path = fallback_path
                    else:
                        # Try iteratively for cases with multiple underscores if needed
                        parts = fname.split('_')
                        for i in range(1, len(parts)):
                            sub_cat = "_".join(parts[:i])
                            try_path = os.path.join(self.image_root, 'images_meg', sub_cat, fname)
                            if os.path.exists(try_path):
                                full_path = try_path
                                break
            
            if full_path:
                try:
                    img = Image.open(full_path).convert('RGB')
                except:
                    img = Image.new('RGB', (512, 512))
            else:
                # Still not found
                img = Image.new('RGB', (512, 512))
        # 2. Transform masking
        tensor_img = self.transform(img)
        tensor_img = tensor_img * 2 - 1  # [0,1] -> [-1, 1]
        
        valid_flag = 1 if rel_path and full_path else 0
        
        return tensor_img, valid_flag

# ==========================================
# 4. ëª¨ë¸ ë¡œë“œ (AutoKL)
# ==========================================
print("ğŸš€ Loading Versatile Diffusion Model (AutoKL)...")
cfgm_name = 'vd_noema'
pth = 'versatile_diffusion/pretrained/vd-four-flow-v1-0-fp16-deprecated.pth' 

if not os.path.exists(pth):
    raise FileNotFoundError(f"Checkpoint not found at {pth}")

cfgm = model_cfg_bank()(cfgm_name)
net = get_model()(cfgm)
sd = torch.load(pth, map_location='cpu')
net.load_state_dict(sd, strict=False)

# ìµœì í™”: ë¶ˆí•„ìš”í•œ ëª¨ë“ˆ ì œê±°
net.clip = None
net.model = None

device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
net.autokl = net.autokl.to(device)
net.autokl.eval() 
net.autokl.half() # FP16

print(f"âœ… AutoKL Model Ready on {device}")

# ==========================================
# 5. ì¶”ì¶œ ë° HDF5 ì €ì¥ í•¨ìˆ˜
# ==========================================
def extract_and_save_hdf5(dataset, save_path):
    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)
    num_samples = len(dataset)
    
    # HDF5 ìƒì„±
    print(f"ğŸ’¾ Creating HDF5: {save_path}")
    print(f"   Target Shape: ({num_samples}, 4, 64, 64)")
    
    total_missing = 0

    with h5py.File(save_path, 'w') as f:
        # FP16ìœ¼ë¡œ ì €ì¥ (ìš©ëŸ‰ 50% ì ˆì•½)
        dset = f.create_dataset('features', shape=(num_samples, 4, 64, 64), dtype='float16', chunks=True)
        
        start_idx = 0
        with torch.no_grad():
            for batch_imgs, batch_valid_flags in tqdm(loader, desc=f"Extracting"):
                batch_imgs = batch_imgs.to(device).half()
                
                # Count missing
                # batch_valid_flags is a tensor of 0s and 1s
                missing_in_batch = (1 - batch_valid_flags).sum().item()
                total_missing += missing_in_batch
                
                # AutoKL Encode
                # autokl_encodeëŠ” (Mean, Logvar)ê°€ ì•„ë‹ˆë¼ Sampled Latentë¥¼ ë°˜í™˜í•¨
                z = net.autokl_encode(batch_imgs) 
                
                # CPUë¡œ ì´ë™ ë° ì €ì¥
                z_np = z.cpu().numpy().astype(np.float16)
                
                batch_len = z_np.shape[0]
                dset[start_idx : start_idx + batch_len] = z_np
                start_idx += batch_len
    
    print(f"âœ… Saved to {save_path}")
    if total_missing > 0:
        print(f"âŒ WARNING: {total_missing} images were NOT FOUND and replaced with black images.")
    else:
        print(f"âœ¨ Success: All {num_samples} images were found and processed.")

# ==========================================
# 6. ë©”ì¸ ì‹¤í–‰ (Train & Test)
# ==========================================

# ------------------------------------------------
# 6-1. Combined Train Feature Extraction
# ------------------------------------------------
train_h5 = os.path.join(args.data_dir, 'train', 'combined_train.h5')
train_out_path = os.path.join(args.out_dir, 'combined_autokl_train.h5')

if os.path.exists(train_h5):
    if not os.path.exists(train_out_path):
        print(f"\nğŸš€ Processing Combined Train Data...")
        train_dataset = HDF5ImageDataset(train_h5, args.image_root)
        extract_and_save_hdf5(train_dataset, train_out_path)
    else:
        print(f"\nâš  Skipping Train: {train_out_path} already exists.")
else:
    print(f"\nğŸš¨ Train HDF5 not found: {train_h5}")

# ------------------------------------------------
# 6-2. Per-Subject Test Feature Extraction
# ------------------------------------------------
subjects = ['P1', 'P2', 'P3', 'P4']

for sub in subjects:
    test_h5 = os.path.join(args.data_dir, 'test', f'{sub}_test.h5')
    
    # ì €ì¥ ê²½ë¡œ: ./data/extracted_features/P1/P1_autokl_test.h5
    sub_out_dir = os.path.join(args.out_dir, sub)
    os.makedirs(sub_out_dir, exist_ok=True)
    test_out_path = os.path.join(sub_out_dir, f'{sub}_autokl_test.h5')
    
    if os.path.exists(test_h5):
        if not os.path.exists(test_out_path):
            print(f"\nğŸš€ Processing Test Data for {sub}...")
            test_dataset = HDF5ImageDataset(test_h5, args.image_root)
            extract_and_save_hdf5(test_dataset, test_out_path)
        else:
            print(f"âš  Skipping {sub}: {test_out_path} already exists.")
    else:
        print(f"ğŸš¨ Test HDF5 not found for {sub}: {test_h5}")

print("\nğŸ‰ All Feature Extractions Finished!")
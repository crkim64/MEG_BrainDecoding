import sys
import os
import torch
import numpy as np
from torch.utils.data import DataLoader
import h5py

# ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (train_brainmodule_autokl_final.pyì™€ ë™ì¼í•˜ê²Œ êµ¬ì„±)
class MEGAutoKLDatasetDebug(torch.utils.data.Dataset):
    def __init__(self, meg_path, autokl_path, subjects):
        self.meg_path = meg_path
        self.autokl_path = autokl_path
        self.subjects = subjects
        with h5py.File(meg_path, 'r') as f:
            self.length = f['meg'].shape[0]
            self.categories = f['category_nr'][:]
            self.exemplars = f['exemplar_nr'][:]
        self.meg_hf = None
        self.autokl_hf = None

    def __len__(self): return self.length

    def __getitem__(self, idx):
        if self.meg_hf is None:
            self.meg_hf = h5py.File(self.meg_path, 'r')
            self.autokl_hf = h5py.File(self.autokl_path, 'r')
            
        meg_data = self.meg_hf['meg'][idx]
        
        # [í•µì‹¬] AutoKL ì½ê¸°
        feat_raw = self.autokl_hf['features'][idx] 
        target_mse = torch.from_numpy(feat_raw.reshape(-1)).float()
        
        # CLIP Target (Mean)
        feat_mean = np.mean(feat_raw, axis=0).reshape(-1)
        target_clip = torch.from_numpy(feat_mean).float()
        
        # SoftCLIP ID
        cat_id = self.categories[idx]
        ex_id = self.exemplars[idx]
        unique_img_id = cat_id * 100 + ex_id
        
        return torch.from_numpy(meg_data), target_clip, target_mse, unique_img_id

def debug_main():
    print("ğŸ•µï¸ Debugging DataLoader...")
    data_dir = './data'
    train_meg = os.path.join(data_dir, 'train/combined_train.h5')
    train_autokl = os.path.join(data_dir, 'extracted_features/combined_autokl_train.h5')
    subjects = ['P1', 'P2', 'P3', 'P4']

    dataset = MEGAutoKLDatasetDebug(train_meg, train_autokl, subjects)
    loader = DataLoader(dataset, batch_size=128, shuffle=True)
    
    print("âœ… Dataset loaded. Fetching first batch...")
    
    try:
        meg, t_clip, t_mse, img_ids = next(iter(loader))
    except Exception as e:
        print(f"ğŸš¨ Error: {e}")
        return

    # 1. Target MSE ê°’ í™•ì¸
    print(f"\nğŸ“Š [Target MSE Stats]")
    print(f"   Shape: {t_mse.shape}")
    print(f"   Min: {t_mse.min().item():.6f}")
    print(f"   Max: {t_mse.max().item():.6f}")
    print(f"   Mean: {t_mse.mean().item():.6f}")
    print(f"   Abs Mean: {t_mse.abs().mean().item():.6f}")
    
    if torch.allclose(t_mse, torch.zeros_like(t_mse), atol=1e-5):
        print("\nğŸš¨ğŸš¨ğŸš¨ [CRITICAL] Target is ALL ZEROS! ë¡œë” ë¬¸ì œì…ë‹ˆë‹¤.")
    else:
        print("\nâœ… Target data looks valid (Not zero).")

    # 2. ì¤‘ë³µ ì´ë¯¸ì§€ í™•ì¸ (SoftCLIP ì‘ë™ ì—¬ë¶€)
    unique_ids, counts = torch.unique(img_ids, return_counts=True)
    num_duplicates = (counts > 1).sum().item()
    print(f"\nğŸ§© [Duplicate Check] Batch Size 128")
    print(f"   Duplicate Groups found: {num_duplicates}")
    if num_duplicates == 0:
        print("âš ï¸ [WARNING] ë°°ì¹˜ ë‚´ì— ê°™ì€ ì´ë¯¸ì§€ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤. SoftCLIPì´ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    debug_main()